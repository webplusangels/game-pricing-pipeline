import requests
import pandas as pd
from bs4 import BeautifulSoup
import time
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from pathlib import Path
from requests.exceptions import HTTPError, Timeout, ConnectionError

from util.io_helper import save_csv
from util.cache_manager import CacheManager
from util.logger import setup_logger
from config import settings

class SteamListFetcher:
    def __init__(self, 
                 output_dir="./data/raw", 
                 cache_dir="./data/cache",
                 error_dir="./data/error",
                 log_dir='./log/fetcher',
                 max_retries=3, 
                 thread_workers=2,
                 steamcharts_games=1000,
                 webapi_key=settings.STEAM_KEY):
        # ------------------------- ì„¤ì • -------------------------
        self.MAX_RETRIES = max_retries
        self.THREAD_WORKERS = thread_workers
        self.STEAMCHARTS_GAMES = steamcharts_games
        self.WEBAPI_KEY = webapi_key
        
        # ë””ë ‰í† ë¦¬ ì„¤ì •
        self.OUTPUT_DIR = Path(output_dir)
        self.OUTPUT_DIR.mkdir(exist_ok=True)
        self.CACHE_DIR = Path(cache_dir)
        self.CACHE_DIR.mkdir(exist_ok=True)
        self.ERROR_DIR = Path(error_dir)
        self.ERROR_DIR.mkdir(exist_ok=True)
        self.LOG_DIR = Path(log_dir)
        self.LOG_DIR.mkdir(exist_ok=True)
        
        # ë¡œê¹… ì„¤ì •
        self.logger = setup_logger(
            name="steam_list_fetcher", 
            log_dir=self.LOG_DIR,
        )
        
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        self.CACHE_FILE_STEAMCHART = self.CACHE_DIR / "steamcharts_status_cache.json"
        self.CACHE_FILE_ALL_APPS = self.CACHE_DIR / "all_apps_cache.json"
        self.FAILED_PAGES_FILE = self.ERROR_DIR / "failed_steamcharts_pages.csv"
        self.steamcharts_path = self.OUTPUT_DIR / "steamcharts_top_games.csv"
        self.all_apps_path = self.OUTPUT_DIR / "all_app_list.csv"
        self.common_ids_path = self.OUTPUT_DIR / "common_ids.csv"
        
        # í—¤ë” ì„¤ì •
        self.HEADERS = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
        }
        
        # ------------------------- ë°ì´í„° ì €ì¥ì†Œ -------------------------
        self.game_data = []
        self.failed_pages = []
        self.cache_steamchart = CacheManager(self.CACHE_FILE_STEAMCHART)
        self.cache_all_apps = CacheManager(self.CACHE_FILE_ALL_APPS)
    
    def scrape_steamcharts_page(self, page_number):
        """ë‹¨ì¼ SteamCharts í˜ì´ì§€ ìŠ¤í¬ë˜í•‘"""
        if self.cache_steamchart.get(page_number) and self.cache_steamchart.get(page_number).get("status") == "success" and not self.cache.is_stale(page_number, hours=24):
            return
        
        base_url = "https://steamcharts.com/top/p.{}"
        url = base_url.format(page_number)
        
        try:
            response = requests.get(url, headers=self.HEADERS, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, "html.parser")
            table = soup.find("table", id="top-games")
            
            if not table:
                self.failed_pages.append(page_number)
                self.cache_steamchart.set(page_number, "no_table")
                self.logger.warning(f"í˜ì´ì§€ {page_number}ì— í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            tbody = table.find("tbody")
            rows = tbody.find_all("tr")
            
            for row in rows:
                rank = row.find("td").text.strip()
                game_td = row.find("td", class_="game-name")
                if game_td:
                    game_link = game_td.find("a")
                    if game_link:
                        appid = game_link["href"].split("/")[-1]
                        game_name = game_link.text.strip()
                        self.game_data.append((rank, appid, game_name))
            
            self.cache_steamchart.set(page_number, { "status": "success" })
            
        except Timeout:
            self.failed_pages.append(page_number)
            self.cache_steamchart.set(page_number, "timeout")
            self.logger.warning(f"[í˜ì´ì§€ {page_number}] ìš”ì²­ íƒ€ì„ì•„ì›ƒ")
            raise
            
        except ConnectionError as e:
            self.failed_pages.append(page_number)
            self.cache_steamchart.set(page_number, "connection_error")
            self.logger.error(f"[í˜ì´ì§€ {page_number}] ì—°ê²° ì˜¤ë¥˜: {e}")
            raise
            
        except HTTPError as e:
            self.failed_pages.append(page_number)
            status_code = getattr(e.response, 'status_code', None)
            self.cache_steamchart.set(page_number, f"http_error_{status_code}")
            
            if status_code == 429:  # Rate limit
                self.logger.warning(f"[í˜ì´ì§€ {page_number}] ìš”ì²­ ì œí•œ ê°ì§€")
            raise
                
        except Exception as e:
            self.failed_pages.append(page_number)
            self.cache_steamchart.set(page_number, "error")
            self.logger.error(f"[í˜ì´ì§€ {page_number}] ì—ëŸ¬ ë°œìƒ: {e}")
            raise
    
    def scrape_steamcharts_parallel(self):
        """í˜ì´ì§€ë¥¼ ë³‘ë ¬ë¡œ ìŠ¤í¬ë˜í•‘"""
        pages_to_scrape = [page for page in range(1, int(self.STEAMCHARTS_GAMES/25) + 1) 
                           if not self.cache_steamchart.get(page) or 
                           self.cache_steamchart.get(page).get("status") != "success" or 
                           self.cache_steamchart.is_stale(page, hours=24)]
        
        with ThreadPoolExecutor(max_workers=self.THREAD_WORKERS) as executor:
            futures = []
            for page in pages_to_scrape:
                futures.append(executor.submit(self.scrape_steamcharts_page, page))
                time.sleep(0.5)  # ìš”ì²­ ê°„ ì§€ì—°
            
            for future in tqdm(as_completed(futures), total=len(futures), desc="ğŸ“¦ Scraping"):
                try:
                    future.result()
                except Exception as e:
                    self.logger.error(f"ìŠ¤ë ˆë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ê²°ê³¼ ì €ì¥
        self.save_steamcharts_results()
    
    def save_steamcharts_results(self):
        """SteamCharts ê²°ê³¼ ì €ì¥"""
        try:
            games_list_df = pd.DataFrame(self.game_data, columns=["rank", "appid", "game_name"])
            save_csv(games_list_df, self.steamcharts_path)
            
            # ìºì‹œì™€ ìƒíƒœ ì €ì¥
            self.cache_steamchart.save()
                        
            # ì‹¤íŒ¨í•œ í˜ì´ì§€ ì €ì¥
            if self.failed_pages:
                failed_pages_df = pd.DataFrame({"page": self.failed_pages})
                save_csv(failed_pages_df, self.FAILED_PAGES_FILE)
            
            self.logger.info(f"âœ… SteamCharts ë°ì´í„° ì €ì¥ ì™„ë£Œ: {self.steamcharts_path}")
            self.logger.info(f"ì´ ìˆ˜ì§‘ëœ ê²Œì„: {len(games_list_df)}")
            self.logger.info(f"ì‹¤íŒ¨í•œ í˜ì´ì§€: {len(self.failed_pages)}")
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def fetch_all_apps(self):
        """Steam APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ì•± ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        if self.cache_all_apps.get("all_apps") and not self.cache_all_apps.is_stale("all_apps", hours=24):
            self.logger.info("â„¹ï¸ ìµœê·¼ 24ì‹œê°„ ë‚´ ìˆ˜ì§‘ëœ ì•± ë¦¬ìŠ¤íŠ¸ê°€ ìˆì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
            return      
        all_apps = []
        last_appid = 0

        while True:
            url = (
                f"https://api.steampowered.com/IStoreService/GetAppList/v1/"
                f"?key={self.WEBAPI_KEY}&include_games=1&include_dlc=0&include_software=0"
                f"&include_videos=0&include_hardware=0&max_results=50000&last_appid={last_appid}"
            )
            try:
                response = requests.get(url)
                response.raise_for_status()
                response_json = response.json()

                if "response" not in response_json:
                    self.logger.error("Error: 'response' key not found in the response JSON")
                    break

                response_data = response_json["response"]
                apps = response_data.get("apps", [])
                all_apps.extend(apps)

                if not response_data.get("have_more_results", False):
                    break

                last_appid = response_data.get("last_appid", 0)

            except Exception as e:
                self.logger.error(f"ì•± ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
                break

        # í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
        parsed_data = [{"appid": app.get("appid"), "name": app.get("name")} for app in all_apps]

        # ì €ì¥
        df = pd.DataFrame(parsed_data)
        save_csv(df, self.all_apps_path)
        self.logger.info(f"âœ… ì „ì²´ ì•± ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {self.all_apps_path}")

        self.cache_all_apps.set(
            "all_apps", {
                "status": "success", 
                "collected_at": datetime.now().isoformat(), 
                "number_of_apps": len(parsed_data) 
            })
        self.cache_all_apps.save()
        
    def filter_common_ids(self):
        """SteamChartsì™€ ì „ì²´ ì•± ë¦¬ìŠ¤íŠ¸ì˜ ê³µí†µ ID í•„í„°ë§"""
        try:
            # íŒŒì¼ ë¡œë“œ
            steamcharts_df = pd.read_csv(self.steamcharts_path)
            all_apps_df = pd.read_csv(self.all_apps_path)
            if self.common_ids_path.exists():
                old_ids_df = pd.read_csv(self.common_ids_path)
            else:
                old_ids_df = pd.DataFrame(columns=["appid", "name"])
                
            # ê³µí†µ ID í•„í„°ë§
            common_ids_df = all_apps_df[all_apps_df["appid"].isin(steamcharts_df["appid"])]
            new_only_df = common_ids_df[~common_ids_df["appid"].isin(old_ids_df["appid"])]
            updated_df = pd.concat([old_ids_df, new_only_df], ignore_index=True).drop_duplicates(subset="appid")
            save_csv(updated_df, self.common_ids_path)
            
            self.logger.info(f"âœ… ê³µí†µ ID ì €ì¥ ì™„ë£Œ: {self.common_ids_path}")
            self.logger.info(f"ê³µí†µ ID ìˆ˜: {len(common_ids_df)}")
        except Exception as e:
            self.logger.error(f"ê³µí†µ ID í•„í„°ë§ ì¤‘ ì˜¤ë¥˜: {e}")

    def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        try:
            self.logger.info("ğŸš€ SteamCharts ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            self.scrape_steamcharts_parallel()

            self.logger.info("ğŸš€ ì „ì²´ ì•± ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹œì‘")
            self.fetch_all_apps()

            self.logger.info("ğŸš€ ê³µí†µ ID í•„í„°ë§ ì‹œì‘")
            self.filter_common_ids()

            self.logger.info("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
